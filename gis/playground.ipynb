{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Class Infomation\n",
    "Class data is collected from the OSU course catalog and the barrett.3 course information website.\n",
    "The OSU course catalog has useful and clean data on where classes/labs/recitations are, their start and end dates, and times;\n",
    "however, their enrollment data is not useful since it aggregates enrollments of all sections of a course into one number.\n",
    "barrett.3's data has enrollment info on each individual section for a course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from datetime import datetime, time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barret_subjects = [\n",
    "    'ACADAFF', 'ACCAD', 'ACCTMIS', 'ACEL', 'AEDECON', 'AEE', 'AEROENG', 'AFAMAST', 'AGRCOMM', 'AGSYSMGT', 'AGSYSMT', 'AIRSCI', 'ALLIMED', 'ANATOMY', 'ANESTHES', 'ANIMSCI', 'ANMLTEC', 'ANTHROP', 'ARABIC', 'ARCH', 'ART', 'ARTEDUC', 'ARTSCOL', 'ARTSSCI', 'ASE', 'ASL', 'ASTRON', 'ATHTRNG', 'ATMOSSC', 'AVIATION', 'AVIATN', 'BCS', 'BIOCHEM', 'BIOCHEMP', 'BIOETHC', 'BIOLOGY', 'BIOMEDE',\n",
    "    'BIOMINF', 'BIOMSCI', 'BIOPHRM', 'BIOPHYS', 'BIOSCI', 'BIOSTAT', 'BIOTECH', 'BIOWMGT', 'BMEA', 'BMI', 'BSGP', 'BUSADM', 'BUSFIN', 'BUSMGT', 'BUSMHR', 'BUSML', 'BUSOBA', 'BUSTEC', 'CATALAN', 'CBE', 'CBG', 'CHBE', 'CHEM', 'CHEMPHY', 'CHINESE', 'CIRTECH', 'CIVILEN', 'CLAS', 'CLASSICS', 'CLLC', 'COMLDR', 'COMM', 'COMPSTD', 'CONSCI', 'CONSYSM', 'CONSYSMT', 'CRPLAN', 'CRPSOIL', 'CSCFFS',\n",
    "    'CSCFMFNS', 'CSE', 'CSFMRSM', 'CSFRST', 'CSFSNRTS', 'CSHSPMG', 'CSTW', 'CSTXTCL', 'CZECH', 'DANCE', 'DENT', 'DENTHYG', 'DESIGN', 'DNE', 'DSABLST', 'EALL', 'EARTHSC', 'EARTHSCI', 'ECE', 'ECON', 'EDUCST', 'EDUPAES', 'EDUPL', 'EDUTL', 'EEOB', 'EEURLL', 'EHE', 'EMERGMED', 'ENGINEER', 'ENGLISH', 'ENGR', 'ENGRAPH', 'ENGREDU', 'ENGRTEC', 'ENGTECH', 'ENR', 'ENTMLGY', 'ENTOMOL', 'ENVENG', 'ENVSCI',\n",
    "    'ENVSCT', 'ESCE', 'ESCFE', 'ESEADM', 'ESEPHL', 'ESEPOL', 'ESEPSY', 'ESETEC', 'ESHESA', 'ESLTECH', 'ESPHE', 'ESQREM', 'ESQUAL', 'ESSPED', 'ESSPSY', 'ESTEPL', 'ESWDE', 'EXP', 'EXPLORNG', 'FABENG', 'FAES', 'FCSED', 'FDSCTE', 'FILMSTD', 'FMRESM', 'FRENCH', 'FRIT', 'GENBIOL', 'GENCHEM', 'GENCOMM', 'GENED', 'GENHUM', 'GENMATH', 'GENSSC', 'GENSTDS', 'GEODSCIE', 'GEODSCIM', 'GEOG', 'GEORGIAN', 'GEOSCIM',\n",
    "    'GERMAN', 'GRADSCH', 'GRADTDA', 'GREEK', 'HCINNOV', 'HCS', 'HDFS', 'HEBREW', 'HECCREG', 'HIMS', 'HINDI', 'HISTART', 'HISTORY', 'HONORS', 'HORTTEC', 'HOSPMGT', 'HSMP', 'HTHRHSC', 'HUMANEC', 'HUMCOL', 'HUMNNTR', 'HUNGARIN', 'HUNGRN', 'HW', 'HWIH', 'IBGP', 'INDENG', 'INTMED', 'INTSTDS', 'ISE', 'ISLAM', 'ITALIAN', 'JAPANESE', 'JAPANSE', 'JEWSHST', 'KINESIO', 'KNHES', 'KNOW', 'KNPE', 'KNSFHP',\n",
    "    'KNSISM', 'KOREAN', 'LABBIOSC', 'LARCH', 'LATIN', 'LAW', 'LING', 'LINGUIST', 'MATH', 'MATSCEN', 'MBA', 'MCDBIO', 'MCR', 'MDN', 'MDRNGRK', 'MEATSCI', 'MECHENG', 'MEDCOLL', 'MEDDIET', 'MEDIEVAL', 'MEDLBS', 'MEDMCIM', 'MEDREN', 'MEDTECH', 'MICRBIO', 'MICRBIOL', 'MILSCI', 'MOLBIOC', 'MOLBIOCH', 'MOLGEN', 'MPSCOL', 'MUSIC', 'MVIMG', 'MVNGIMG', 'NAVALSC', 'NELC', 'NEURO',\n",
    "    'NEUROGS', 'NEUROGSP', 'NEUROSC', 'NEURSGY', 'NRSADVN', 'NRSPRCT', 'NUCLREN', 'NURSING', 'NURSPRCT', 'OCCTHER', 'OPTHLMOL', 'OPTOM', 'OPTOMTRY', 'ORIENTAT', 'OSBP', 'OTOLARN', 'OTOLARYN', 'PATHOL', 'PDATRICS', 'PEDS', 'PERSIAN', 'PHARMACY', 'PHARMCL', 'PHARMCOL', 'PHILOS', 'PHR', 'PHYSICS', 'PHYSIO', 'PHYSIOCB', 'PHYSMED', 'PHYSTHER', 'PHYSTHR', 'PLNTBIO', 'PLNTPTH', 'POLISH', 'POLITSC', 'PORTGESE',\n",
    "    'PORTGSE', 'PSYBHLH', 'PSYCH', 'PSYCHTRY', 'PUBAFRS', 'PUBHBIO', 'PUBHEHS', 'PUBHEPI', 'PUBHHBP', 'PUBHHMP', 'PUBHLTH', 'PUBPOLM', 'QUECHUA', 'RADIOLG', 'RADIOLGY', 'RADSCI', 'RELSTDS', 'RESPTHER', 'RESPTHR', 'RNEWNRG', 'ROMANIA', 'ROMANIAN', 'ROMLING', 'ROOM', 'RURLSOC', 'RUSSIAN', 'SANSKRIT', 'SANSKRT', 'SASIA', 'SBSCOL', 'SCANDNAV', 'SCANDVN', 'SCHOLAR', 'SLAVIC', 'SOCIOL', 'SOCWORK', 'SOMALI',\n",
    "    'SPANISH', 'SPHHRNG', 'SRBCROA', 'STAT', 'STEP', 'SUMMARY', 'SURGERY', 'SWAHILI', 'SWEDISH', 'SXLTYST', 'TECPHYS', 'THEATRE', 'TIBETAN', 'TURKISH', 'TXTLCLO', 'URDU', 'USAS', 'UZBEK', 'VETBIOS', 'VETCLIN', 'VETPREV', 'VISSCI', 'VMCOLL', 'VOCEDUC', 'WELDENG', 'WGSST', 'WOMSTDS', 'YIDDISH', 'YORUBA', 'ZULU'\n",
    "]\n",
    "\n",
    "url = 'https://content.osu.edu/v2/classes/search'\n",
    "params = {\n",
    "    'q': '', # Query\n",
    "    'client': 'class-search-ui',\n",
    "    'campus': 'col',\n",
    "    'term': 1252, # SP25=1252, SU25=1254, AU25=1258\n",
    "    'p': 1, # Page\n",
    "    'subject': ''\n",
    "}\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:136.0) Gecko/20100101 Firefox/136.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "    'Origin': 'https://classes.osu.edu',\n",
    "    'DNT': '1',\n",
    "    'Sec-GPC': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://classes.osu.edu/',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-site',\n",
    "    'Priority': 'u=0'\n",
    "}\n",
    "\n",
    "osu_subjects = []\n",
    "with open('osu_subjects.json', 'r') as f:\n",
    "    osu_subjects_info = json.load(f)\n",
    "for s in osu_subjects_info:\n",
    "    osu_subjects.append(s['term'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Data from OSU Course Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_items = 0\n",
    "all_courses = []\n",
    "all_sections = []\n",
    "for subject in osu_subjects:\n",
    "    current_page = 1\n",
    "    subject_courses = []\n",
    "    subject_sections = []\n",
    "    params['subject'] = subject\n",
    "    params['p'] = current_page\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, params, headers=headers)\n",
    "    except TimeoutError as er:\n",
    "        print(f'Timed out on subject {subject} on page {current_page}')\n",
    "        sleep(5)\n",
    "    if r.status_code != 200:\n",
    "        print(f'ERROR {r.status_code} getting subject: \"{subject}\"')\n",
    "        continue\n",
    "    data = r.json()['data']\n",
    "    subject_total_items = data['totalItems']\n",
    "    total_items += subject_total_items\n",
    "    total_pages = data['totalPages']\n",
    "\n",
    "    while current_page <= total_pages:\n",
    "        subject_courses.extend(data['courses'])\n",
    "        current_page += 1\n",
    "        params['p'] = current_page\n",
    "        try:\n",
    "            r = requests.get(url, params, headers=headers)\n",
    "        except TimeoutError as er:\n",
    "            print(f'Timed out on subject {subject} on page {current_page}')\n",
    "            sleep(5)\n",
    "        if r.status_code != 200:\n",
    "            print(f'ERROR {r.status_code} getting subject: \"{subject}\" at page ')\n",
    "            continue\n",
    "        data = r.json()['data']\n",
    "    \n",
    "    for course in subject_courses:\n",
    "        for section in course['sections']:\n",
    "            section['catalogNumber'] = f'{course['subject']} {course['catalogNumber']}'\n",
    "            section['title'] = course['title']\n",
    "            subject_sections.append(section)\n",
    "\n",
    "    if len(subject_sections) != subject_total_items:\n",
    "        print(f'{subject} item count mismatch. Expected {subject_total_items}, found {len(subject_sections)} items')\n",
    "        continue\n",
    "    all_courses.extend(subject_courses)\n",
    "    all_sections.extend(subject_sections)\n",
    "    sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sections = []\n",
    "for course_info in all_courses:\n",
    "    course = course_info['course']\n",
    "    for section in course_info['sections']:\n",
    "        section['catalogNumber'] = f'{course['subject']} {course['catalogNumber']}'\n",
    "        section['title'] = course['title']\n",
    "        all_sections.append(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meetings = []\n",
    "for section in all_sections:\n",
    "    for meeting in section['meetings']:\n",
    "        if 'instructors' in meeting:\n",
    "            meeting.pop('instructors')\n",
    "        meeting['term'] = section['term']\n",
    "        meeting['catalogId'] = section['catalogNumber']\n",
    "        meeting['classTitle'] = section['title']\n",
    "        meeting['classNumber'] = section['classNumber']\n",
    "        meeting['section'] = section['section']\n",
    "        meeting['sectionEnrollment'] = section['enrollmentTotal']\n",
    "        all_meetings.append(meeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetings_df = pd.DataFrame(all_meetings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_sections\n",
    "del section\n",
    "del meeting\n",
    "del course\n",
    "del course_info\n",
    "del r\n",
    "del f\n",
    "del s\n",
    "del subject_courses\n",
    "del subject_sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Data from barrett.3's Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and save text files\n",
    "for s in barret_subjects:\n",
    "    url = f'https://www.asc.ohio-state.edu/barrett.3/schedule/{s}/{params['term']}.txt'\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        print(f'{r.status_code}\\t{s}')\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join('Courses', f'{s}.txt'), 'wb') as course_file:\n",
    "        course_file.write(r.content)\n",
    "    sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each text file and convert to into a dataframe\n",
    "course_files = os.listdir('Courses')\n",
    "column_widths = [20, 10, 2, 17, 9, 12, 11, 7, 100]\n",
    "colspec = [\n",
    "    (0, 20),\n",
    "    (20, 25),\n",
    "    (25, 31),\n",
    "    (31, 34),\n",
    "    (34, 49),\n",
    "    (49, 58),\n",
    "    (59, 70),\n",
    "    (70, 81),\n",
    "    (81, 89),\n",
    "    (89, 94),\n",
    "    (94, 200)\n",
    "]\n",
    "all_courses_df = pd.DataFrame()\n",
    "for course_file_name in course_files:\n",
    "    footer_start = 0\n",
    "    path = os.path.join('Courses', course_file_name)\n",
    "    with open(path, 'r') as course_file:\n",
    "        for line_num, line in enumerate(course_file, start=1):\n",
    "            if \"INDependent study classes\" in line:\n",
    "                footer_start = line_num\n",
    "    \n",
    "    if not footer_start:\n",
    "        skipfooter = 0\n",
    "    else:\n",
    "        skipfooter = line_num - footer_start + 1\n",
    "    \n",
    "    df = pd.read_fwf(path, skipfooter=skipfooter, skiprows=3, header=None, colspecs=colspec)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df = df.dropna(subset=0).reset_index(drop=True)\n",
    "    df.rename({\n",
    "            0: 'course',\n",
    "            1: 'campus',\n",
    "            2: 'class_number',\n",
    "            3: 'component',\n",
    "            4: 'auto_enrolls',\n",
    "            5: 'days',\n",
    "            6: 'times',\n",
    "            7: 'location',\n",
    "            8: 'enrolled_status',\n",
    "            9: 'waitlist',\n",
    "            10: 'instructor'\n",
    "        }, inplace=True, axis=1\n",
    "    )\n",
    "    df[['enrolled', 'limit']] = df['enrolled_status'].str.split('/', expand=True)\n",
    "    df.drop('enrolled_status', axis=1, inplace=True)\n",
    "    all_courses_df = pd.concat([all_courses_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all online courses and regional campus courses\n",
    "all_courses_df.drop_duplicates(inplace=True)\n",
    "filtered_courses = all_courses_df[\n",
    "    (all_courses_df['location'] != 'ONLINE') &\n",
    "    (all_courses_df['enrolled'] != '0') &\n",
    "    (all_courses_df['campus'].isnull()) &\n",
    "    (all_courses_df['location'].notnull())\n",
    "]\n",
    "filtered_courses = filtered_courses.astype({\n",
    "    'enrolled': 'Int16',\n",
    "    'limit': 'Int16',\n",
    "    'class_number': 'Int32'\n",
    "})\n",
    "filtered_courses = filtered_courses[['course', 'class_number', 'enrolled', 'limit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetings_df = meetings_df.astype({\n",
    "    'classNumber': 'Int32',\n",
    "    'sectionEnrollment': 'Int32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two data sets, some courses are lost in this process but it's negligible\n",
    "merged = pd.merge(\n",
    "    left=filtered_courses,\n",
    "    right=meetings_df,\n",
    "    left_on='class_number',\n",
    "    right_on='classNumber',\n",
    "    how='inner'\n",
    ")\n",
    "merged = merged[\n",
    "    (merged['facilityDescription'] != 'ONLINE') &\n",
    "    (merged['facilityDescription'].notnull())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('class_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all the downloaded files\n",
    "shutil.rmtree('Courses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Traffic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split sidewalk centerline data into segments so that it can be graded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import split\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
